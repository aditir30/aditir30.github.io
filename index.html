<!DOCTYPE HTML>
<html>

<head>
	<title>Resume</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper" class="fade-in">

		<!-- Intro -->
		<div id="intro">
			<h2>Aditi Anil Raghuwanshi</h2>
			<p>Computer Science Graduate Student at University of North Carolina Charlotte | Former Big Data Engineer at Barclays India </p>
			<p><strong>  Phone: +1(704)819-3078 <span style="margin-left:30px;">Email: <a href="mailto:raghuwanshi.aditi30@gmail.com">raghuwanshi.aditi30@gmail.com</a></span> </strong></p>
			<ul class="actions">
				<li><a href="#nav" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
			</ul>
		</div>



		<!-- Nav -->
		<nav id="nav">
			<ul class="links">
				<li class="active"><a href="#main">ABOUT</a></li>
				<li><a href="#education">EDUCATION</a></li>
				<li><a href="#experience">EXPERIENCE</a></li>
				<li><a href="#skills">TECHNICAL SKILLS</a></li>
				<li><a href="#project">PROJECTS</a></li>
				<li><a href="#activities">ACTIVITIES</a></li>
				<li><a href="#contact">CONTACT</a></li>
			</ul>
			<ul class="icons">
				<li><a href="https://www.linkedin.com/in/aditi-raghuwanshi/" class="icon brands fa-linkedin"><span
							class="label">LinkedIn</span></a></li>
				<li><a href="https://github.com/aditir30" class="icon brands fa-github"><span
							class="label">Github</span></a></li>
			</ul>
		</nav>

		<!-- Main -->
		<div id="main">

			<!-- Featured Post -->
			<article class="post featured">
				<header class="major">
					<p>
						Big Data Engineer offering 3+ years of experience working with Barclays on data technologies, including Hadoop, Spark, Kafka, Hive, and Impala. Currently pursuing Master's in Computer Science at University of North Carolina Charlotte 
						and seeking full time opportunities in data engineering or business intelligence domain.
					</p>
				</header>
				</header>
			</article>

			<section id="education">
				<h2>Education</h2>
				<hr>
				<h3>Bachelor Of Technology in Computer Engineering    <small><span style="float:right;">Jun 2013 – May 2017</span></small></h3>
				<p>College of Engineering, Pune, MH, India
					<br>
					<small>CGPA: 3.8/4.0</small>
					<br>
					
				</p>
				<h3>Master of Science in Computer Science   <small><span style="float:right;">Jan 2021 - May 2022</span></small></h3>
				<p>University Of North Carolina, Charlotte, NC, USA
					<br>
					<small>CGPA: 4.0/4.0</small>
					<br>
					
				</p>
			</section>

			<section id="experience">
				<h2>Experience</h2>
				<hr>
				
				<h3><i> Graduate Research Assistant, Urban Institute, University of North Carolina Charlotte, USA</i> 		<small><span style="float:right;">Jan 2022 – present</span></small></h3>
				<ul>
					<li> <b>Technologies:</b> R, MySQL, Shell Scripting</li>
					<li><b>Responsibilites:</b></li>
					<ul class="square-list">
						<li>Create data pipelines to clean and store data for various research projects.</li>
						<li>Management of research data and perform statistical analysis to answer research questions.</li>
						<li>Design schema for metadata management for all the available databases handled by the department.</li>
						<li>Managing metadata documentation such that users could refer to it for better understanding of research data.</li>
					</ul>
				</ul>
				<hr>
				<h3> <i> Big Data Engineer, Barclays, Pune, INDIA</i> 		<small><span style="float:right">Jul 2017 – Dec 2020</span></small></h3>
				<h4>Project #1: Real-time Data Warehousing</h4>

				<ul>
					<li> <b>Technologies:</b> Hadoop, Scala, Spark, Kafka, Kudu, Unix, DevOps, Agile, Scrum</li>
					<li><b>Responsibilites:</b></li>
					<ul class="square-list">
						<li>Developed scalable streaming workflow to fetch enterprise data from Kafka queues using 
							Apache Spark, perform data transformation (ETL) and load to Kudu data store.</li>
						<li>Optimized streaming pipelines to gain 40% performance improvement and ensure real-time availability of data for analysis.</li>
						<li>Designed and developed audit and reconciliation framework to log and monitor data processing pipelines and provide roll-back feature in case of issues or failures. 
							This resulted in <strong>70% time saving</strong> in data post-processing as compared to legacy applications.</li>
						<li>Developed Unix scripts integrating SQL to query Kudu tables to fetch data, create reports and send across business personnel.</li>
						<li>Act as primary point-of-contact for product development teams as well as for various testing and code deployment teams.</li>
						<li>Designed technical documentation and standards for onboarding uses cases that required real-time processing.</li>
						<li>Core member of Centre of Excellence team for development, testing, code reviews and deployment of new use-cases.</li>
					</ul>
				</ul>

				<h4>Project #2: History data Amendment utility</h4>
				<ul>
					<li> <b>Technologies:</b> Scala, Unix, SparkSQL, Parquet</li>
					<li><b>Responsibilites:</b></li>
					<ul class="square-list">
						<li>Design and developed a configurable file driven utility that will modify and/or update data in cases where table schema and/or table data need to be changed. 
							This brought down the time required from <strong>months to weeks.</strong></li>
						<li>Conducted sessions and design discussions across business units to deliver the utility as per stakeholder requirements.</li>
					</ul>
				</ul>
			</section>

			<!-- Posts -->
			<section id="skills">
				<h2>Technical Skills and Highlights</h2>
				<hr>
				<ul>
					<li><strong>Programming Languages/Framework:</strong> Java, Scala, SQL, PostgreSQL, Shell, R, Python, HTML5, CSS3, Android</li>
					<li><strong>Databases:</strong> MS SQL Server, Apache Hive, Apache Kudu, Firebase, MongoDB</li>
					<li><strong>Technologies:</strong> Hadoop, HBase, Pig, Spark, Apache Kafka, Parquet, Pandas, Matplotlib, Azure, AWS</li>
					<li><strong>Tools/Lib/IDE:</strong> IntelliJ, Jenkins, Bit Bucket, Git, UNIX, Confluence, JIRA, IBM Tivoli, Tableau</li>
				</ul>
			</section>

			<section id="project">
				<h2>Academic and Personal Projects</h2>
				<hr>
				<ul>
					<li> <strong>Recommender system using Collaborative Filtering:</strong>
						<ul>
							<p>Developed a movie recommendation system using Python (without the use of available APIs) that utilizes computation power of Spark. 
							The system was implemented using two of the collaborative filtering algorithms – item-based and Singular Value Decomposition.</p>
						</ul>
					</li>
				</ul>
				<ul>
					<li> <strong>Linear Regression using PySpark:</strong>
						<ul>
							<p>Implemented Linear Regression mathematical model using Ordinary Least Squared approach using Python and Apache Spark.</p>
						</ul>
					</li>
				</ul>
				<ul>
					<li> <strong>Minimum wages through ages:</strong>
						<ul>
							<p>The aim of the project was to create an interactive multiform visualization system using the minimum wages dataset available on Kaggle.
							The analysis was done using python packages of Altair and Streamlit to visualize the results/trends.
							This project is deployed on Heroku and available at - <a href="https://uncc-va-streamlit.herokuapp.com/">Heroku App</a> </p>
						</ul>
					</li>
				</ul>
				<ul>
					<li> <strong>Forum Application:</strong>
						<ul>
							<p>The purpose of this Android application was to allow users to create new forums, like/unlike forums, delete forums and add comments to forums.
							The signup and authentication were done by Google Firebase. Additionally, Firebase was used to store and manage forum data </p>
						</ul>
					</li>
				</ul>
				<ul>
					<li> <strong>Coupon Recommendation System using Machine Learning Models:</strong>
						<ul>
							<p>The aim of the project was to predict the type of coupon to recommend to customers
							based on certain attributes known about the person. The prediction was performed
							using SVM and Random Forest Classifiers. Accuracy of the model was improved from 80%
							to <b>90%</b> using hyperparameter tuning.</p>
						</ul>
					</li>
				</ul>
				<ul>
					<li> <strong>COVID-19 trends in India:</strong>
						<ul>
							<p>The aim of the project was to analyze COVID-19 data for medical presentations. The analysis was done using Tidyverse package of R to ingest, transform and analyze COVID-19 datasets available in India. To plot the results/trends, GGPlot2 was used.</p>
						</ul>
					</li>
				</ul>
				<ul>
					<li> <strong>Optimization of performance parameters on Hadoop:</strong>
						<ul>
							<p>The aim of the project was to tune parameters which affect performance of Hadoop and achieve maximum throughput. The project was done as part of fulfillment of Bachelor of Technology in Computer Engineering.</p>
						</ul>
					</li>
				</ul>
			</section>
			
			
			<section id="activities">
				<h2>Activities</h2>
				<hr>
				<ul class="square-list">
					<li>Volunteering for career guidance session for final year engineering students at Barclays.</li>
					<li>Finance Head for the 88th edition of the boatclub event Regatta.</li>
					<li>Participated in the College Boat Club Event - Regatta, in the event Shell Games (Rowing).</li>
					<li>Worked in the Electronics System Management team as a volunteer for MindSpark, 2013.</li>
				</ul>
			</section>

			<section id="contact">
				<h2>Contact Detail</h2>
				<hr>
				
				<p> <strong>Address: </strong> 9523 University Terrace Drive, Apt M, Charlotte, NC, USA
					<br>
					<small><strong>Phone: </strong>  +1(704)819-3078</small>
					<br>
					<small><strong>Email: </strong>  <a href="mailto:raghuwanshi.aditi30@gmail.com">raghuwanshi.aditi30@gmail.com</a></small>
					<br>
				</p>
			</section>

		</div>
		<div id="copyright">

		</div>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>
